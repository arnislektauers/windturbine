{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.0954462  -0.20987126 -0.07504695 ...  9.7360336   0.07377332\n",
      "   0.04958158]\n",
      " [ 8.0954462  -0.20987126 -0.07504695 ...  9.7360336   0.07377332\n",
      "   0.04958158]\n",
      " [ 8.0954462  -0.20987126 -0.07504695 ...  9.7360336   0.07377332\n",
      "   0.04958158]\n",
      " ...\n",
      " [ 8.0954462  -0.20987126 -0.07504695 ...  9.7360336   0.07377332\n",
      "   0.04958158]\n",
      " [ 8.0954462  -0.20987126 -0.07504695 ...  9.7360336   0.07377332\n",
      "   0.04958158]\n",
      " [ 8.0954462  -0.20987126 -0.07504695 ...  9.7360336   0.07377332\n",
      "   0.04958158]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\IlzeA\\\\Desktop\\\\DB2\")\n",
    "\n",
    "data = np.zeros((12000, 3993))\n",
    "\n",
    "for i in range (1, 12001):\n",
    "    \n",
    "    df = pd.read_table(\"matrix_\" + str(i) + \".dat\", sep=\",\", header = None)\n",
    "    df = df.to_numpy()\n",
    "    data[i-1] = df.flatten()\n",
    "    \n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File label_9609.dat does not exist: 'label_9609.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-42b6fc9bf684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"label_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".dat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File label_9609.dat does not exist: 'label_9609.dat'"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\IlzeA\\\\Desktop\\\\DB2\")\n",
    "\n",
    "labels = np.zeros((12000, 1))\n",
    "\n",
    "for i in range (1, 12001):\n",
    "    \n",
    "    df = pd.read_table(\"label_\" + str(i) + \".dat\", sep=\",\", header = None)\n",
    "    df = df.to_numpy()\n",
    "    df = df[0]\n",
    "    labels[i-1] = df.flatten()\n",
    "    \n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 17,651\n",
      "Trainable params: 17,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "import keras as keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu', input_dim = 300))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(Dense(units = 1, activation = None))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=optim, loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21 samples, validate on 6 samples\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 0s 236us/step - loss: 0.3618 - mean_squared_error: 0.3618 - val_loss: 0.3284 - val_mean_squared_error: 0.3284\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32839, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.2902 - mean_squared_error: 0.2902 - val_loss: 0.4697 - val_mean_squared_error: 0.4697\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.32839\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.5030 - mean_squared_error: 0.5030 - val_loss: 0.6093 - val_mean_squared_error: 0.6093\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32839\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.6689 - mean_squared_error: 0.6689 - val_loss: 0.5504 - val_mean_squared_error: 0.5504\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.32839\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 235us/step - loss: 0.5520 - mean_squared_error: 0.5520 - val_loss: 0.4484 - val_mean_squared_error: 0.4484\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.32839\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.3977 - mean_squared_error: 0.3977 - val_loss: 0.3526 - val_mean_squared_error: 0.3526\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.32839\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.2306 - mean_squared_error: 0.2306 - val_loss: 0.3241 - val_mean_squared_error: 0.3241\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.32839 to 0.32409, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.2452 - mean_squared_error: 0.2452 - val_loss: 0.3305 - val_mean_squared_error: 0.3305\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.32409\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.2123 - mean_squared_error: 0.2123 - val_loss: 0.3438 - val_mean_squared_error: 0.3438\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32409\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.2458 - mean_squared_error: 0.2458 - val_loss: 0.3418 - val_mean_squared_error: 0.3418\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32409\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1975 - mean_squared_error: 0.1975 - val_loss: 0.3261 - val_mean_squared_error: 0.3261\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32409\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 191us/step - loss: 0.2308 - mean_squared_error: 0.2308 - val_loss: 0.3159 - val_mean_squared_error: 0.3159\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.32409 to 0.31594, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.2556 - mean_squared_error: 0.2556 - val_loss: 0.3197 - val_mean_squared_error: 0.3197\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.31594\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1853 - mean_squared_error: 0.1853 - val_loss: 0.3359 - val_mean_squared_error: 0.3359\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.31594\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 191us/step - loss: 0.1829 - mean_squared_error: 0.1829 - val_loss: 0.3407 - val_mean_squared_error: 0.3407\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.31594\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.2134 - mean_squared_error: 0.2134 - val_loss: 0.3382 - val_mean_squared_error: 0.3382\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31594\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.2021 - mean_squared_error: 0.2021 - val_loss: 0.3292 - val_mean_squared_error: 0.3292\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31594\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1935 - mean_squared_error: 0.1935 - val_loss: 0.3156 - val_mean_squared_error: 0.3156\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.31594 to 0.31563, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.2093 - mean_squared_error: 0.2093 - val_loss: 0.3089 - val_mean_squared_error: 0.3089\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.31563 to 0.30887, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1710 - mean_squared_error: 0.1710 - val_loss: 0.3091 - val_mean_squared_error: 0.3091\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.30887\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1937 - mean_squared_error: 0.1937 - val_loss: 0.3109 - val_mean_squared_error: 0.3109\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.30887\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1932 - mean_squared_error: 0.1932 - val_loss: 0.3083 - val_mean_squared_error: 0.3083\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.30887 to 0.30825, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 236us/step - loss: 0.1685 - mean_squared_error: 0.1685 - val_loss: 0.3043 - val_mean_squared_error: 0.3043\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.30825 to 0.30427, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.1945 - mean_squared_error: 0.1945 - val_loss: 0.2996 - val_mean_squared_error: 0.2996\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.30427 to 0.29960, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.1851 - mean_squared_error: 0.1851 - val_loss: 0.2974 - val_mean_squared_error: 0.2974\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.29960 to 0.29742, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1762 - mean_squared_error: 0.1762 - val_loss: 0.2960 - val_mean_squared_error: 0.2960\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.29742 to 0.29596, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1746 - mean_squared_error: 0.1746 - val_loss: 0.2961 - val_mean_squared_error: 0.2961\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.29596\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.2002 - mean_squared_error: 0.2002 - val_loss: 0.2962 - val_mean_squared_error: 0.2962\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.29596\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.2100 - mean_squared_error: 0.2100 - val_loss: 0.2930 - val_mean_squared_error: 0.2930\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.29596 to 0.29297, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1691 - mean_squared_error: 0.1691 - val_loss: 0.2904 - val_mean_squared_error: 0.2904\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.29297 to 0.29041, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.1877 - mean_squared_error: 0.1877 - val_loss: 0.2880 - val_mean_squared_error: 0.2880\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.29041 to 0.28803, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 0.1801 - mean_squared_error: 0.1801 - val_loss: 0.2858 - val_mean_squared_error: 0.2858\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.28803 to 0.28578, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1755 - mean_squared_error: 0.1755 - val_loss: 0.2836 - val_mean_squared_error: 0.2836\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.28578 to 0.28364, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1896 - mean_squared_error: 0.1896 - val_loss: 0.2817 - val_mean_squared_error: 0.2817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from 0.28364 to 0.28173, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 35/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1630 - mean_squared_error: 0.1630 - val_loss: 0.2804 - val_mean_squared_error: 0.2804\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.28173 to 0.28035, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1744 - mean_squared_error: 0.1744 - val_loss: 0.2785 - val_mean_squared_error: 0.2785\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.28035 to 0.27847, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1657 - mean_squared_error: 0.1657 - val_loss: 0.2761 - val_mean_squared_error: 0.2761\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.27847 to 0.27607, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1710 - mean_squared_error: 0.1710 - val_loss: 0.2750 - val_mean_squared_error: 0.2750\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.27607 to 0.27501, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1584 - mean_squared_error: 0.1584 - val_loss: 0.2754 - val_mean_squared_error: 0.2754\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.27501\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1547 - mean_squared_error: 0.1547 - val_loss: 0.2769 - val_mean_squared_error: 0.2769\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.27501\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1519 - mean_squared_error: 0.1519 - val_loss: 0.2792 - val_mean_squared_error: 0.2792\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.27501\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1611 - mean_squared_error: 0.1611 - val_loss: 0.2811 - val_mean_squared_error: 0.2811\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.27501\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1648 - mean_squared_error: 0.1648 - val_loss: 0.2798 - val_mean_squared_error: 0.2798\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.27501\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1609 - mean_squared_error: 0.1609 - val_loss: 0.2765 - val_mean_squared_error: 0.2765\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.27501\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1590 - mean_squared_error: 0.1590 - val_loss: 0.2748 - val_mean_squared_error: 0.2748\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.27501 to 0.27478, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.1572 - mean_squared_error: 0.1572 - val_loss: 0.2726 - val_mean_squared_error: 0.2726\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.27478 to 0.27256, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1617 - mean_squared_error: 0.1617 - val_loss: 0.2682 - val_mean_squared_error: 0.2682\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.27256 to 0.26821, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1470 - mean_squared_error: 0.1470 - val_loss: 0.2641 - val_mean_squared_error: 0.2641\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.26821 to 0.26414, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1469 - mean_squared_error: 0.1469 - val_loss: 0.2610 - val_mean_squared_error: 0.2610\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.26414 to 0.26099, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.2585 - val_mean_squared_error: 0.2585\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.26099 to 0.25851, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1530 - mean_squared_error: 0.1530 - val_loss: 0.2571 - val_mean_squared_error: 0.2571\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.25851 to 0.25709, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1332 - mean_squared_error: 0.1332 - val_loss: 0.2547 - val_mean_squared_error: 0.2547\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.25709 to 0.25466, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1462 - mean_squared_error: 0.1462 - val_loss: 0.2529 - val_mean_squared_error: 0.2529\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.25466 to 0.25294, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1484 - mean_squared_error: 0.1484 - val_loss: 0.2529 - val_mean_squared_error: 0.2529\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.25294 to 0.25293, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1437 - mean_squared_error: 0.1437 - val_loss: 0.2535 - val_mean_squared_error: 0.2535\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.25293\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1369 - mean_squared_error: 0.1369 - val_loss: 0.2535 - val_mean_squared_error: 0.2535\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.25293\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1384 - mean_squared_error: 0.1384 - val_loss: 0.2535 - val_mean_squared_error: 0.2535\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.25293\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1432 - mean_squared_error: 0.1432 - val_loss: 0.2542 - val_mean_squared_error: 0.2542\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.25293\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1451 - mean_squared_error: 0.1451 - val_loss: 0.2546 - val_mean_squared_error: 0.2546\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.25293\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1327 - mean_squared_error: 0.1327 - val_loss: 0.2537 - val_mean_squared_error: 0.2537\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.25293\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1430 - mean_squared_error: 0.1430 - val_loss: 0.2498 - val_mean_squared_error: 0.2498\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.25293 to 0.24975, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.1403 - mean_squared_error: 0.1403 - val_loss: 0.2435 - val_mean_squared_error: 0.2435\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.24975 to 0.24354, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1295 - mean_squared_error: 0.1295 - val_loss: 0.2391 - val_mean_squared_error: 0.2391\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.24354 to 0.23910, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1389 - mean_squared_error: 0.1389 - val_loss: 0.2382 - val_mean_squared_error: 0.2382\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.23910 to 0.23818, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1443 - mean_squared_error: 0.1443 - val_loss: 0.2405 - val_mean_squared_error: 0.2405\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.23818\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1620 - mean_squared_error: 0.1620 - val_loss: 0.2452 - val_mean_squared_error: 0.2452\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.23818\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1862 - mean_squared_error: 0.1862 - val_loss: 0.2371 - val_mean_squared_error: 0.2371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00067: val_loss improved from 0.23818 to 0.23714, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 332us/step - loss: 0.1626 - mean_squared_error: 0.1626 - val_loss: 0.2276 - val_mean_squared_error: 0.2276\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.23714 to 0.22756, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1410 - mean_squared_error: 0.1410 - val_loss: 0.2255 - val_mean_squared_error: 0.2255\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.22756 to 0.22550, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1362 - mean_squared_error: 0.1362 - val_loss: 0.2300 - val_mean_squared_error: 0.2300\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.22550\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1201 - mean_squared_error: 0.1201 - val_loss: 0.2338 - val_mean_squared_error: 0.2338\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.22550\n",
      "Epoch 72/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1238 - mean_squared_error: 0.1238 - val_loss: 0.2319 - val_mean_squared_error: 0.2319\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.22550\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1227 - mean_squared_error: 0.1227 - val_loss: 0.2277 - val_mean_squared_error: 0.2277\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.22550\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1167 - mean_squared_error: 0.1167 - val_loss: 0.2234 - val_mean_squared_error: 0.2234\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.22550 to 0.22339, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 236us/step - loss: 0.1238 - mean_squared_error: 0.1238 - val_loss: 0.2193 - val_mean_squared_error: 0.2193\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.22339 to 0.21928, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1255 - mean_squared_error: 0.1255 - val_loss: 0.2165 - val_mean_squared_error: 0.2165\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.21928 to 0.21646, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1130 - mean_squared_error: 0.1130 - val_loss: 0.2144 - val_mean_squared_error: 0.2144\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.21646 to 0.21440, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1211 - mean_squared_error: 0.1211 - val_loss: 0.2144 - val_mean_squared_error: 0.2144\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.21440\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1123 - mean_squared_error: 0.1123 - val_loss: 0.2167 - val_mean_squared_error: 0.2167\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.21440\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1324 - mean_squared_error: 0.1324 - val_loss: 0.2181 - val_mean_squared_error: 0.2181\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.21440\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.1186 - mean_squared_error: 0.1186 - val_loss: 0.2189 - val_mean_squared_error: 0.2189\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.21440\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1211 - mean_squared_error: 0.1211 - val_loss: 0.2187 - val_mean_squared_error: 0.2187\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.21440\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 0.1123 - mean_squared_error: 0.1123 - val_loss: 0.2172 - val_mean_squared_error: 0.2172\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.21440\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1271 - mean_squared_error: 0.1271 - val_loss: 0.2149 - val_mean_squared_error: 0.2149\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.21440\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 0.1183 - mean_squared_error: 0.1183 - val_loss: 0.2104 - val_mean_squared_error: 0.2104\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.21440 to 0.21043, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.1119 - mean_squared_error: 0.1119 - val_loss: 0.2050 - val_mean_squared_error: 0.2050\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.21043 to 0.20501, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 0.1061 - mean_squared_error: 0.1061 - val_loss: 0.1996 - val_mean_squared_error: 0.1996\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.20501 to 0.19964, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1143 - mean_squared_error: 0.1143 - val_loss: 0.1965 - val_mean_squared_error: 0.1965\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.19964 to 0.19653, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1163 - mean_squared_error: 0.1163 - val_loss: 0.1940 - val_mean_squared_error: 0.1940\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.19653 to 0.19397, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 236us/step - loss: 0.1063 - mean_squared_error: 0.1063 - val_loss: 0.1917 - val_mean_squared_error: 0.1917\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.19397 to 0.19166, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1105 - mean_squared_error: 0.1105 - val_loss: 0.1899 - val_mean_squared_error: 0.1899\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.19166 to 0.18990, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1168 - mean_squared_error: 0.1168 - val_loss: 0.1885 - val_mean_squared_error: 0.1885\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.18990 to 0.18849, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0951 - mean_squared_error: 0.0951 - val_loss: 0.1857 - val_mean_squared_error: 0.1857\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.18849 to 0.18567, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1120 - mean_squared_error: 0.1120 - val_loss: 0.1853 - val_mean_squared_error: 0.1853\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.18567 to 0.18533, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0975 - mean_squared_error: 0.0975 - val_loss: 0.1857 - val_mean_squared_error: 0.1857\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.18533\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0995 - mean_squared_error: 0.0995 - val_loss: 0.1857 - val_mean_squared_error: 0.1857\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.18533\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1093 - mean_squared_error: 0.1093 - val_loss: 0.1844 - val_mean_squared_error: 0.1844\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.18533 to 0.18438, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.1003 - mean_squared_error: 0.1003 - val_loss: 0.1832 - val_mean_squared_error: 0.1832\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.18438 to 0.18324, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1009 - mean_squared_error: 0.1009 - val_loss: 0.1834 - val_mean_squared_error: 0.1834\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.18324\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1094 - mean_squared_error: 0.1094 - val_loss: 0.1847 - val_mean_squared_error: 0.1847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_loss did not improve from 0.18324\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0984 - mean_squared_error: 0.0984 - val_loss: 0.1861 - val_mean_squared_error: 0.1861\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.18324\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1091 - mean_squared_error: 0.1091 - val_loss: 0.1872 - val_mean_squared_error: 0.1872\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.18324\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.1005 - mean_squared_error: 0.1005 - val_loss: 0.1864 - val_mean_squared_error: 0.1864\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.18324\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.1162 - mean_squared_error: 0.1162 - val_loss: 0.1826 - val_mean_squared_error: 0.1826\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.18324 to 0.18261, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.1005 - mean_squared_error: 0.1005 - val_loss: 0.1771 - val_mean_squared_error: 0.1771\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.18261 to 0.17706, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1034 - mean_squared_error: 0.1034 - val_loss: 0.1717 - val_mean_squared_error: 0.1717\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.17706 to 0.17172, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0898 - mean_squared_error: 0.0898 - val_loss: 0.1686 - val_mean_squared_error: 0.1686\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.17172 to 0.16863, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0932 - mean_squared_error: 0.0932 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.16863 to 0.16716, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 109/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0972 - mean_squared_error: 0.0972 - val_loss: 0.1659 - val_mean_squared_error: 0.1659\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.16716 to 0.16588, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0842 - mean_squared_error: 0.0842 - val_loss: 0.1644 - val_mean_squared_error: 0.1644\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.16588 to 0.16444, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0875 - mean_squared_error: 0.0875 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.16444 to 0.16281, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0853 - mean_squared_error: 0.0853 - val_loss: 0.1610 - val_mean_squared_error: 0.1610\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.16281 to 0.16096, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0788 - mean_squared_error: 0.0788 - val_loss: 0.1596 - val_mean_squared_error: 0.1596\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.16096 to 0.15961, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0939 - mean_squared_error: 0.0939 - val_loss: 0.1565 - val_mean_squared_error: 0.1565\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.15961 to 0.15648, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0825 - mean_squared_error: 0.0825 - val_loss: 0.1522 - val_mean_squared_error: 0.1522\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.15648 to 0.15216, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1056 - mean_squared_error: 0.1056 - val_loss: 0.1514 - val_mean_squared_error: 0.1514\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.15216 to 0.15138, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0820 - mean_squared_error: 0.0820 - val_loss: 0.1550 - val_mean_squared_error: 0.1550\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.15138\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0960 - mean_squared_error: 0.0960 - val_loss: 0.1535 - val_mean_squared_error: 0.1535\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.15138\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0930 - mean_squared_error: 0.0930 - val_loss: 0.1503 - val_mean_squared_error: 0.1503\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.15138 to 0.15032, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0950 - mean_squared_error: 0.0950 - val_loss: 0.1480 - val_mean_squared_error: 0.1480\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.15032 to 0.14796, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0754 - mean_squared_error: 0.0754 - val_loss: 0.1466 - val_mean_squared_error: 0.1466\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.14796 to 0.14665, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0755 - mean_squared_error: 0.0755 - val_loss: 0.1450 - val_mean_squared_error: 0.1450\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.14665 to 0.14500, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0770 - mean_squared_error: 0.0770 - val_loss: 0.1438 - val_mean_squared_error: 0.1438\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.14500 to 0.14379, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0728 - mean_squared_error: 0.0728 - val_loss: 0.1427 - val_mean_squared_error: 0.1427\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.14379 to 0.14268, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0746 - mean_squared_error: 0.0746 - val_loss: 0.1414 - val_mean_squared_error: 0.1414\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.14268 to 0.14145, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0758 - mean_squared_error: 0.0758 - val_loss: 0.1406 - val_mean_squared_error: 0.1406\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.14145 to 0.14057, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0793 - mean_squared_error: 0.0793 - val_loss: 0.1378 - val_mean_squared_error: 0.1378\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.14057 to 0.13785, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0770 - mean_squared_error: 0.0770 - val_loss: 0.1326 - val_mean_squared_error: 0.1326\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.13785 to 0.13261, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0696 - mean_squared_error: 0.0696 - val_loss: 0.1323 - val_mean_squared_error: 0.1323\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.13261 to 0.13233, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0763 - mean_squared_error: 0.0763 - val_loss: 0.1327 - val_mean_squared_error: 0.1327\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.13233\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0821 - mean_squared_error: 0.0821 - val_loss: 0.1277 - val_mean_squared_error: 0.1277\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.13233 to 0.12774, saving model to saved_models/weights_test_data_1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0657 - mean_squared_error: 0.0657 - val_loss: 0.1248 - val_mean_squared_error: 0.1248\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.12774 to 0.12484, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0668 - mean_squared_error: 0.0668 - val_loss: 0.1233 - val_mean_squared_error: 0.1233\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.12484 to 0.12335, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0643 - mean_squared_error: 0.0643 - val_loss: 0.1226 - val_mean_squared_error: 0.1226\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.12335 to 0.12259, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0568 - mean_squared_error: 0.0568 - val_loss: 0.1232 - val_mean_squared_error: 0.1232\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.12259\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0723 - mean_squared_error: 0.0723 - val_loss: 0.1213 - val_mean_squared_error: 0.1213\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.12259 to 0.12130, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0616 - mean_squared_error: 0.0616 - val_loss: 0.1194 - val_mean_squared_error: 0.1194\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.12130 to 0.11937, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0827 - mean_squared_error: 0.0827 - val_loss: 0.1207 - val_mean_squared_error: 0.1207\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.11937\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0744 - mean_squared_error: 0.0744 - val_loss: 0.1243 - val_mean_squared_error: 0.1243\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.11937\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0964 - mean_squared_error: 0.0964 - val_loss: 0.1315 - val_mean_squared_error: 0.1315\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.11937\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.1093 - mean_squared_error: 0.1093 - val_loss: 0.1356 - val_mean_squared_error: 0.1356\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.11937\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 0.0977 - mean_squared_error: 0.0977 - val_loss: 0.1284 - val_mean_squared_error: 0.1284\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.11937\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0853 - mean_squared_error: 0.0853 - val_loss: 0.1204 - val_mean_squared_error: 0.1204\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.11937\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0729 - mean_squared_error: 0.0729 - val_loss: 0.1162 - val_mean_squared_error: 0.1162\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.11937 to 0.11624, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0725 - mean_squared_error: 0.0725 - val_loss: 0.1149 - val_mean_squared_error: 0.1149\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.11624 to 0.11489, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 146/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0683 - mean_squared_error: 0.0683 - val_loss: 0.1140 - val_mean_squared_error: 0.1140\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.11489 to 0.11402, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0725 - mean_squared_error: 0.0725 - val_loss: 0.1133 - val_mean_squared_error: 0.1133\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.11402 to 0.11329, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0682 - mean_squared_error: 0.0682 - val_loss: 0.1126 - val_mean_squared_error: 0.1126\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.11329 to 0.11257, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0800 - mean_squared_error: 0.0800 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.11257 to 0.11111, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0648 - mean_squared_error: 0.0648 - val_loss: 0.1082 - val_mean_squared_error: 0.1082\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.11111 to 0.10822, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0733 - mean_squared_error: 0.0733 - val_loss: 0.1038 - val_mean_squared_error: 0.1038\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.10822 to 0.10383, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0525 - mean_squared_error: 0.0525 - val_loss: 0.0992 - val_mean_squared_error: 0.0992\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.10383 to 0.09917, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0589 - mean_squared_error: 0.0589 - val_loss: 0.0957 - val_mean_squared_error: 0.0957\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.09917 to 0.09566, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.0932 - val_mean_squared_error: 0.0932\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.09566 to 0.09320, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0504 - mean_squared_error: 0.0504 - val_loss: 0.0920 - val_mean_squared_error: 0.0920\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.09320 to 0.09202, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0592 - mean_squared_error: 0.0592 - val_loss: 0.0912 - val_mean_squared_error: 0.0912\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.09202 to 0.09118, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0796 - mean_squared_error: 0.0796 - val_loss: 0.0892 - val_mean_squared_error: 0.0892\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.09118 to 0.08918, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0573 - mean_squared_error: 0.0573 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.08918 to 0.08881, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0549 - mean_squared_error: 0.0549 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.08881 to 0.08844, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0517 - mean_squared_error: 0.0517 - val_loss: 0.0878 - val_mean_squared_error: 0.0878\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.08844 to 0.08780, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0536 - mean_squared_error: 0.0536 - val_loss: 0.0874 - val_mean_squared_error: 0.0874\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.08780 to 0.08744, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 0.0505 - mean_squared_error: 0.0505 - val_loss: 0.0884 - val_mean_squared_error: 0.0884\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.08744\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0460 - mean_squared_error: 0.0460 - val_loss: 0.0908 - val_mean_squared_error: 0.0908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00163: val_loss did not improve from 0.08744\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0713 - mean_squared_error: 0.0713 - val_loss: 0.0925 - val_mean_squared_error: 0.0925\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.08744\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0506 - mean_squared_error: 0.0506 - val_loss: 0.0931 - val_mean_squared_error: 0.0931\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.08744\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0910 - val_mean_squared_error: 0.0910\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.08744\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0491 - mean_squared_error: 0.0491 - val_loss: 0.0864 - val_mean_squared_error: 0.0864\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.08744 to 0.08643, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 236us/step - loss: 0.0481 - mean_squared_error: 0.0481 - val_loss: 0.0831 - val_mean_squared_error: 0.0831\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.08643 to 0.08311, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0493 - mean_squared_error: 0.0493 - val_loss: 0.0832 - val_mean_squared_error: 0.0832\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.08311\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0466 - mean_squared_error: 0.0466 - val_loss: 0.0827 - val_mean_squared_error: 0.0827\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.08311 to 0.08270, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0528 - mean_squared_error: 0.0528 - val_loss: 0.0820 - val_mean_squared_error: 0.0820\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.08270 to 0.08203, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0523 - mean_squared_error: 0.0523 - val_loss: 0.0816 - val_mean_squared_error: 0.0816\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.08203 to 0.08159, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0472 - mean_squared_error: 0.0472 - val_loss: 0.0814 - val_mean_squared_error: 0.0814\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.08159 to 0.08136, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 0.0508 - mean_squared_error: 0.0508 - val_loss: 0.0809 - val_mean_squared_error: 0.0809\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.08136 to 0.08094, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.0802 - val_mean_squared_error: 0.0802\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.08094 to 0.08024, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.08024 to 0.07974, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 188us/step - loss: 0.0447 - mean_squared_error: 0.0447 - val_loss: 0.0788 - val_mean_squared_error: 0.0788\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.07974 to 0.07877, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0485 - mean_squared_error: 0.0485 - val_loss: 0.0769 - val_mean_squared_error: 0.0769\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.07877 to 0.07689, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0536 - mean_squared_error: 0.0536 - val_loss: 0.0755 - val_mean_squared_error: 0.0755\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.07689 to 0.07554, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0745 - val_mean_squared_error: 0.0745\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.07554 to 0.07445, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0486 - mean_squared_error: 0.0486 - val_loss: 0.0735 - val_mean_squared_error: 0.0735\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.07445 to 0.07348, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0417 - mean_squared_error: 0.0417 - val_loss: 0.0726 - val_mean_squared_error: 0.0726\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.07348 to 0.07261, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 183/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0604 - mean_squared_error: 0.0604 - val_loss: 0.0721 - val_mean_squared_error: 0.0721\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.07261 to 0.07206, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0447 - mean_squared_error: 0.0447 - val_loss: 0.0715 - val_mean_squared_error: 0.0715\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.07206 to 0.07152, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.0705 - val_mean_squared_error: 0.0705\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.07152 to 0.07050, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0508 - mean_squared_error: 0.0508 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.07050 to 0.06973, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0705 - val_mean_squared_error: 0.0705\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.06973\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0731 - val_mean_squared_error: 0.0731\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.06973\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0720 - val_mean_squared_error: 0.0720\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.06973\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0459 - mean_squared_error: 0.0459 - val_loss: 0.0693 - val_mean_squared_error: 0.0693\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.06973 to 0.06930, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0415 - mean_squared_error: 0.0415 - val_loss: 0.0656 - val_mean_squared_error: 0.0656\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.06930 to 0.06563, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0488 - mean_squared_error: 0.0488 - val_loss: 0.0631 - val_mean_squared_error: 0.0631\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.06563 to 0.06311, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0404 - mean_squared_error: 0.0404 - val_loss: 0.0618 - val_mean_squared_error: 0.0618\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.06311 to 0.06182, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.06182 to 0.06132, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 195/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 190us/step - loss: 0.0435 - mean_squared_error: 0.0435 - val_loss: 0.0681 - val_mean_squared_error: 0.0681\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.06132\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0868 - val_mean_squared_error: 0.0868\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.06132\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 0.0599 - mean_squared_error: 0.0599 - val_loss: 0.0858 - val_mean_squared_error: 0.0858\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.06132\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0646 - mean_squared_error: 0.0646 - val_loss: 0.0693 - val_mean_squared_error: 0.0693\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.06132\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0615 - val_mean_squared_error: 0.0615\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.06132\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 0.0455 - mean_squared_error: 0.0455 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.06132 to 0.05943, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.05943\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0417 - mean_squared_error: 0.0417 - val_loss: 0.0600 - val_mean_squared_error: 0.0600\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.05943\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0687 - mean_squared_error: 0.0687 - val_loss: 0.0597 - val_mean_squared_error: 0.0597\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.05943\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0509 - mean_squared_error: 0.0509 - val_loss: 0.0590 - val_mean_squared_error: 0.0590\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.05943 to 0.05903, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 0.0591 - val_mean_squared_error: 0.0591\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.05903\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0429 - mean_squared_error: 0.0429 - val_loss: 0.0599 - val_mean_squared_error: 0.0599\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.05903\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.05903 to 0.05826, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 0.0557 - val_mean_squared_error: 0.0557\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.05826 to 0.05568, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0431 - mean_squared_error: 0.0431 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.05568 to 0.05438, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0546 - val_mean_squared_error: 0.0546\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.05438\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0540 - mean_squared_error: 0.0540 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.05438 to 0.05353, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0599 - mean_squared_error: 0.0599 - val_loss: 0.0526 - val_mean_squared_error: 0.0526\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.05353 to 0.05261, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0540 - val_mean_squared_error: 0.0540\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.05261\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0409 - mean_squared_error: 0.0409 - val_loss: 0.0579 - val_mean_squared_error: 0.0579\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.05261\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.05261\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0551 - val_mean_squared_error: 0.0551\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.05261\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0674 - mean_squared_error: 0.0674 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.05261\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.05261\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.05261\n",
      "Epoch 220/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0568 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.05261\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0526 - mean_squared_error: 0.0526 - val_loss: 0.0630 - val_mean_squared_error: 0.0630\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.05261\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0635 - val_mean_squared_error: 0.0635\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.05261\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 332us/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0591 - val_mean_squared_error: 0.0591\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.05261\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0433 - mean_squared_error: 0.0433 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.05261\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0473 - val_mean_squared_error: 0.0473\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.05261 to 0.04731, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 332us/step - loss: 0.0549 - mean_squared_error: 0.0549 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.04731\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.04731\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0399 - mean_squared_error: 0.0399 - val_loss: 0.0600 - val_mean_squared_error: 0.0600\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.04731\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0571 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.04731\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0484 - val_mean_squared_error: 0.0484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00230: val_loss did not improve from 0.04731\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0501 - val_mean_squared_error: 0.0501\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.04731\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0609 - val_mean_squared_error: 0.0609\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.04731\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0470 - mean_squared_error: 0.0470 - val_loss: 0.0688 - val_mean_squared_error: 0.0688\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.04731\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0506 - mean_squared_error: 0.0506 - val_loss: 0.0701 - val_mean_squared_error: 0.0701\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.04731\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0437 - mean_squared_error: 0.0437 - val_loss: 0.0572 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.04731\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.04731 to 0.04225, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0413 - mean_squared_error: 0.0413 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.04225 to 0.04196, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.04196\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.04196 to 0.04087, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0622 - mean_squared_error: 0.0622 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.04087\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0647 - val_mean_squared_error: 0.0647\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.04087\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0524 - mean_squared_error: 0.0524 - val_loss: 0.0759 - val_mean_squared_error: 0.0759\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.04087\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0640 - mean_squared_error: 0.0640 - val_loss: 0.0655 - val_mean_squared_error: 0.0655\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.04087\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0600 - mean_squared_error: 0.0600 - val_loss: 0.0550 - val_mean_squared_error: 0.0550\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.04087\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.04087\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.04087 to 0.03910, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.03910 to 0.03762, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0529 - mean_squared_error: 0.0529 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.03762 to 0.03745, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0387 - val_mean_squared_error: 0.0387\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.03745\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0394 - mean_squared_error: 0.0394 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.03745\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.03745\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0694 - mean_squared_error: 0.0694 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.03745\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0606 - val_mean_squared_error: 0.0606\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.03745\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.0511 - val_mean_squared_error: 0.0511\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.03745\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0620 - mean_squared_error: 0.0620 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.03745 to 0.03716, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0346 - val_mean_squared_error: 0.0346\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.03716 to 0.03460, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 257/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0548 - mean_squared_error: 0.0548 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.03460\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0595 - mean_squared_error: 0.0595 - val_loss: 0.0345 - val_mean_squared_error: 0.0345\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.03460 to 0.03448, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.03448\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.03448\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0566 - mean_squared_error: 0.0566 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.03448\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.03448\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.03448\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.03448\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0439 - mean_squared_error: 0.0439 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.03448\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0503 - mean_squared_error: 0.0503 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.03448\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.03448\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.03448\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0557 - val_mean_squared_error: 0.0557\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.03448\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0661 - mean_squared_error: 0.0661 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.03448\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.03448\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.03448\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0343 - val_mean_squared_error: 0.0343\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.03448 to 0.03435, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.03435 to 0.03398, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0514 - mean_squared_error: 0.0514 - val_loss: 0.0338 - val_mean_squared_error: 0.0338\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.03398 to 0.03385, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0343 - val_mean_squared_error: 0.0343\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.03385\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.03385\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.03385\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.03385\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0460 - mean_squared_error: 0.0460 - val_loss: 0.0388 - val_mean_squared_error: 0.0388\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.03385\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.03385\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.03385 to 0.03334, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.03334 to 0.03184, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 0.0566 - mean_squared_error: 0.0566 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.03184 to 0.03160, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.03160\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0438 - mean_squared_error: 0.0438 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.03160\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.03160\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.03160\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0695 - mean_squared_error: 0.0695 - val_loss: 0.0491 - val_mean_squared_error: 0.0491\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.03160\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0610 - mean_squared_error: 0.0610 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.03160\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0301 - val_mean_squared_error: 0.0301\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.03160 to 0.03012, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.03012\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0720 - mean_squared_error: 0.0720 - val_loss: 0.0334 - val_mean_squared_error: 0.0334\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.03012\n",
      "Epoch 294/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0561 - mean_squared_error: 0.0561 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.03012\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.03012\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 0.0570 - mean_squared_error: 0.0570 - val_loss: 0.0640 - val_mean_squared_error: 0.0640\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.03012\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0632 - mean_squared_error: 0.0632 - val_loss: 0.0625 - val_mean_squared_error: 0.0625\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.03012\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 0.0607 - mean_squared_error: 0.0607 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.03012\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.03012\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 0.0614 - mean_squared_error: 0.0614 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.03012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db247650b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 300\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights_test_data_1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer, history], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1db258f7f28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['val_loss'], color = 'blue', label = \"Validation loss\")\n",
    "plt.plot(history.history['loss'], color = 'orange', label = \"Training loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate test data\n",
      "3/3 [==============================] - 0s 0us/step\n",
      "test loss, test acc: [0.040081556886434555, 0.040081556886434555]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate test data\")\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for test data\n",
      "[[ 0.24337012]\n",
      " [-0.15033299]\n",
      " [ 0.596983  ]]\n",
      "Test data\n",
      "[[0.2398]\n",
      " [0.05  ]\n",
      " [0.88  ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions for test data\")\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "print(\"Test data\")\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
