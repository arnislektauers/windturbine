{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.9633641e-01 -3.0457142e-04  1.2127538e-03 ...  9.6707571e-01\n",
      "  -1.4281706e-03  1.6839671e-03]\n",
      " [ 1.7926729e+00 -6.0914279e-04  2.4255282e-03 ...  1.9341514e+00\n",
      "  -2.8563411e-03  3.3679459e-03]\n",
      " [ 2.6890093e+00 -9.1371415e-04  3.6383026e-03 ...  2.9012272e+00\n",
      "  -4.2845117e-03  5.0519247e-03]\n",
      " ...\n",
      " [ 2.5204844e+01  8.1913525e-04 -2.2467139e-04 ...  2.7125985e+01\n",
      "  -1.6332443e-03  1.0689106e-03]\n",
      " [ 2.6105335e+01  8.7596433e-04 -3.2738884e-04 ...  2.8094916e+01\n",
      "  -1.5770190e-03  9.7391294e-04]\n",
      " [ 2.7005815e+01  9.3183640e-04 -4.2642689e-04 ...  2.9063843e+01\n",
      "  -1.5246717e-03  8.8376163e-04]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\IlzeA\\\\Dropbox\\\\Horizon2020\\\\DB1\")\n",
    "\n",
    "data = np.zeros((30, 300))\n",
    "\n",
    "for i in range (1, 31):\n",
    "    \n",
    "    df = pd.read_table(\"matrix_\" + str(i) + \".dat\", sep=\",\", header = None)\n",
    "    df = df.to_numpy()\n",
    "    data[i-1] = df.flatten()\n",
    "    \n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6485]\n",
      " [ 1.2971]\n",
      " [ 1.9456]\n",
      " [ 2.5942]\n",
      " [ 3.3369]\n",
      " [ 4.1136]\n",
      " [ 4.8266]\n",
      " [ 5.5303]\n",
      " [ 6.2917]\n",
      " [ 7.148 ]\n",
      " [ 8.1481]\n",
      " [ 9.2089]\n",
      " [10.3037]\n",
      " [11.3844]\n",
      " [12.4522]\n",
      " [13.4972]\n",
      " [14.5101]\n",
      " [15.5053]\n",
      " [16.4788]\n",
      " [17.4262]\n",
      " [18.3805]\n",
      " [19.3043]\n",
      " [20.2262]\n",
      " [21.1519]\n",
      " [22.0815]\n",
      " [23.0143]\n",
      " [23.9352]\n",
      " [24.8256]\n",
      " [25.7327]\n",
      " [26.639 ]]\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(\"C:\\\\Users\\\\IlzeA\\\\Dropbox\\\\Horizon2020\\\\DB1\")\n",
    "\n",
    "labels = np.zeros((30, 1))\n",
    "\n",
    "for i in range (1, 31):\n",
    "    \n",
    "    df = pd.read_table(\"label_\" + str(i) + \".dat\", sep=\",\", header = None)\n",
    "    df = df.to_numpy()\n",
    "    df = df[1]\n",
    "    labels[i-1] = df.flatten()\n",
    "    \n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 17,651\n",
      "Trainable params: 17,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "import keras as keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu', input_dim = 300))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(Dense(units = 50, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "model.add(Dense(units = 1, activation = None))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=optim, loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21 samples, validate on 6 samples\n",
      "Epoch 1/300\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 246.7706 - mean_squared_error: 246.7706 - val_loss: 94.6435 - val_mean_squared_error: 94.6435\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 94.64352, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 2/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 171.0351 - mean_squared_error: 171.0351 - val_loss: 60.3743 - val_mean_squared_error: 60.3743\n",
      "\n",
      "Epoch 00002: val_loss improved from 94.64352 to 60.37433, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 3/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 114.6150 - mean_squared_error: 114.6150 - val_loss: 32.2606 - val_mean_squared_error: 32.2606\n",
      "\n",
      "Epoch 00003: val_loss improved from 60.37433 to 32.26059, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 4/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 58.4802 - mean_squared_error: 58.4802 - val_loss: 11.0164 - val_mean_squared_error: 11.0164\n",
      "\n",
      "Epoch 00004: val_loss improved from 32.26059 to 11.01641, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 5/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 27.5374 - mean_squared_error: 27.5374 - val_loss: 0.9777 - val_mean_squared_error: 0.9777\n",
      "\n",
      "Epoch 00005: val_loss improved from 11.01641 to 0.97768, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 6/300\n",
      "21/21 [==============================] - 0s 192us/step - loss: 3.8806 - mean_squared_error: 3.8806 - val_loss: 5.4198 - val_mean_squared_error: 5.4198\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97768\n",
      "Epoch 7/300\n",
      "21/21 [==============================] - 0s 189us/step - loss: 6.8298 - mean_squared_error: 6.8298 - val_loss: 19.1419 - val_mean_squared_error: 19.1419\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97768\n",
      "Epoch 8/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 31.0029 - mean_squared_error: 31.0029 - val_loss: 26.6477 - val_mean_squared_error: 26.6477\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.97768\n",
      "Epoch 9/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 45.3034 - mean_squared_error: 45.3034 - val_loss: 26.3028 - val_mean_squared_error: 26.3028\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97768\n",
      "Epoch 10/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 44.9865 - mean_squared_error: 44.9865 - val_loss: 17.2733 - val_mean_squared_error: 17.2733\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.97768\n",
      "Epoch 11/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 37.3296 - mean_squared_error: 37.3296 - val_loss: 5.5036 - val_mean_squared_error: 5.5036\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.97768\n",
      "Epoch 12/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 17.7278 - mean_squared_error: 17.7278 - val_loss: 0.6829 - val_mean_squared_error: 0.6829\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.97768 to 0.68290, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 13/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.1765 - mean_squared_error: 6.1765 - val_loss: 2.9596 - val_mean_squared_error: 2.9596\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.68290\n",
      "Epoch 14/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 6.3968 - mean_squared_error: 6.3968 - val_loss: 8.1504 - val_mean_squared_error: 8.1504\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.68290\n",
      "Epoch 15/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 30.8351 - mean_squared_error: 30.8351 - val_loss: 11.3445 - val_mean_squared_error: 11.3445\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.68290\n",
      "Epoch 16/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 21.3418 - mean_squared_error: 21.3418 - val_loss: 10.6935 - val_mean_squared_error: 10.6935\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.68290\n",
      "Epoch 17/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 14.1984 - mean_squared_error: 14.1984 - val_loss: 7.1218 - val_mean_squared_error: 7.1218\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.68290\n",
      "Epoch 18/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 19.6131 - mean_squared_error: 19.6131 - val_loss: 3.2482 - val_mean_squared_error: 3.2482\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.68290\n",
      "Epoch 19/300\n",
      "21/21 [==============================] - 0s 240us/step - loss: 21.0164 - mean_squared_error: 21.0164 - val_loss: 1.0171 - val_mean_squared_error: 1.0171\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.68290\n",
      "Epoch 20/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 11.8241 - mean_squared_error: 11.8241 - val_loss: 0.8897 - val_mean_squared_error: 0.8897\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.68290\n",
      "Epoch 21/300\n",
      "21/21 [==============================] - 0s 236us/step - loss: 8.6463 - mean_squared_error: 8.6463 - val_loss: 3.8040 - val_mean_squared_error: 3.8040\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.68290\n",
      "Epoch 22/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 11.7933 - mean_squared_error: 11.7933 - val_loss: 8.5985 - val_mean_squared_error: 8.5985\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.68290\n",
      "Epoch 23/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 16.8943 - mean_squared_error: 16.8943 - val_loss: 11.5019 - val_mean_squared_error: 11.5019\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.68290\n",
      "Epoch 24/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 28.1937 - mean_squared_error: 28.1937 - val_loss: 10.5219 - val_mean_squared_error: 10.5219\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.68290\n",
      "Epoch 25/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 14.5662 - mean_squared_error: 14.5662 - val_loss: 7.5104 - val_mean_squared_error: 7.5104\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.68290\n",
      "Epoch 26/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 13.3709 - mean_squared_error: 13.3709 - val_loss: 3.9187 - val_mean_squared_error: 3.9187\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.68290\n",
      "Epoch 27/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.9161 - mean_squared_error: 7.9161 - val_loss: 1.5804 - val_mean_squared_error: 1.5804\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.68290\n",
      "Epoch 28/300\n",
      "21/21 [==============================] - 0s 144us/step - loss: 6.3271 - mean_squared_error: 6.3271 - val_loss: 0.7240 - val_mean_squared_error: 0.7240\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.68290\n",
      "Epoch 29/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.3480 - mean_squared_error: 4.3480 - val_loss: 0.7121 - val_mean_squared_error: 0.7121\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.68290\n",
      "Epoch 30/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.6744 - mean_squared_error: 6.6744 - val_loss: 1.0631 - val_mean_squared_error: 1.0631\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.68290\n",
      "Epoch 31/300\n",
      "21/21 [==============================] - 0s 332us/step - loss: 5.9445 - mean_squared_error: 5.9445 - val_loss: 1.3445 - val_mean_squared_error: 1.3445\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.68290\n",
      "Epoch 32/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.6003 - mean_squared_error: 5.6003 - val_loss: 1.2748 - val_mean_squared_error: 1.2748\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.68290\n",
      "Epoch 33/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 12.8044 - mean_squared_error: 12.8044 - val_loss: 0.8401 - val_mean_squared_error: 0.8401\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.68290\n",
      "Epoch 34/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.0822 - mean_squared_error: 4.0822 - val_loss: 0.6346 - val_mean_squared_error: 0.6346\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.68290 to 0.63464, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 333us/step - loss: 4.7442 - mean_squared_error: 4.7442 - val_loss: 0.7161 - val_mean_squared_error: 0.7161\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.63464\n",
      "Epoch 36/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.5894 - mean_squared_error: 4.5894 - val_loss: 0.8606 - val_mean_squared_error: 0.8606\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.63464\n",
      "Epoch 37/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.9554 - mean_squared_error: 5.9554 - val_loss: 0.7129 - val_mean_squared_error: 0.7129\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.63464\n",
      "Epoch 38/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.3228 - mean_squared_error: 5.3228 - val_loss: 0.6469 - val_mean_squared_error: 0.6469\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.63464\n",
      "Epoch 39/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 6.5494 - mean_squared_error: 6.5494 - val_loss: 0.9390 - val_mean_squared_error: 0.9390\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.63464\n",
      "Epoch 40/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 10.8701 - mean_squared_error: 10.8701 - val_loss: 1.2455 - val_mean_squared_error: 1.2455\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.63464\n",
      "Epoch 41/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.8953 - mean_squared_error: 7.8953 - val_loss: 1.2826 - val_mean_squared_error: 1.2826\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.63464\n",
      "Epoch 42/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 6.4663 - mean_squared_error: 6.4663 - val_loss: 1.1681 - val_mean_squared_error: 1.1681\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.63464\n",
      "Epoch 43/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.2976 - mean_squared_error: 5.2976 - val_loss: 0.9697 - val_mean_squared_error: 0.9697\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.63464\n",
      "Epoch 44/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 10.2273 - mean_squared_error: 10.2273 - val_loss: 0.7963 - val_mean_squared_error: 0.7963\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.63464\n",
      "Epoch 45/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.8129 - mean_squared_error: 4.8129 - val_loss: 0.6181 - val_mean_squared_error: 0.6181\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.63464 to 0.61810, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 46/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.2374 - mean_squared_error: 6.2374 - val_loss: 1.6087 - val_mean_squared_error: 1.6087\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.61810\n",
      "Epoch 47/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.8494 - mean_squared_error: 6.8494 - val_loss: 4.3292 - val_mean_squared_error: 4.3292\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.61810\n",
      "Epoch 48/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 13.9777 - mean_squared_error: 13.9777 - val_loss: 6.1131 - val_mean_squared_error: 6.1131\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.61810\n",
      "Epoch 49/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 14.8068 - mean_squared_error: 14.8068 - val_loss: 6.0210 - val_mean_squared_error: 6.0210\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.61810\n",
      "Epoch 50/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.4404 - mean_squared_error: 9.4404 - val_loss: 4.1243 - val_mean_squared_error: 4.1243\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.61810\n",
      "Epoch 51/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 11.9798 - mean_squared_error: 11.9798 - val_loss: 2.0157 - val_mean_squared_error: 2.0157\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.61810\n",
      "Epoch 52/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.6486 - mean_squared_error: 8.6486 - val_loss: 0.7545 - val_mean_squared_error: 0.7545\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.61810\n",
      "Epoch 53/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.1536 - mean_squared_error: 5.1536 - val_loss: 0.9622 - val_mean_squared_error: 0.9622\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.61810\n",
      "Epoch 54/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 3.6515 - mean_squared_error: 3.6515 - val_loss: 2.5529 - val_mean_squared_error: 2.5529\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.61810\n",
      "Epoch 55/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.9363 - mean_squared_error: 9.9363 - val_loss: 3.8744 - val_mean_squared_error: 3.8744\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.61810\n",
      "Epoch 56/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 12.7282 - mean_squared_error: 12.7282 - val_loss: 4.2759 - val_mean_squared_error: 4.2759\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.61810\n",
      "Epoch 57/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 13.8467 - mean_squared_error: 13.8467 - val_loss: 3.5123 - val_mean_squared_error: 3.5123\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.61810\n",
      "Epoch 58/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 16.4269 - mean_squared_error: 16.4269 - val_loss: 2.0579 - val_mean_squared_error: 2.0579\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.61810\n",
      "Epoch 59/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 15.8928 - mean_squared_error: 15.8928 - val_loss: 0.8985 - val_mean_squared_error: 0.8985\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.61810\n",
      "Epoch 60/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 7.8402 - mean_squared_error: 7.8402 - val_loss: 0.7342 - val_mean_squared_error: 0.7342\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.61810\n",
      "Epoch 61/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.7500 - mean_squared_error: 5.7500 - val_loss: 2.3243 - val_mean_squared_error: 2.3243\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.61810\n",
      "Epoch 62/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 11.3227 - mean_squared_error: 11.3227 - val_loss: 3.8343 - val_mean_squared_error: 3.8343\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.61810\n",
      "Epoch 63/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 10.4980 - mean_squared_error: 10.4980 - val_loss: 3.3060 - val_mean_squared_error: 3.3060\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.61810\n",
      "Epoch 64/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 11.4301 - mean_squared_error: 11.4301 - val_loss: 1.3685 - val_mean_squared_error: 1.3685\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.61810\n",
      "Epoch 65/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.3346 - mean_squared_error: 6.3346 - val_loss: 0.6129 - val_mean_squared_error: 0.6129\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.61810 to 0.61290, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 66/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 4.8470 - mean_squared_error: 4.8470 - val_loss: 2.0245 - val_mean_squared_error: 2.0245\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.61290\n",
      "Epoch 67/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.1520 - mean_squared_error: 9.1520 - val_loss: 3.9513 - val_mean_squared_error: 3.9513\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.61290\n",
      "Epoch 68/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.5295 - mean_squared_error: 5.5295 - val_loss: 4.5877 - val_mean_squared_error: 4.5877\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.61290\n",
      "Epoch 69/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 10.0130 - mean_squared_error: 10.0130 - val_loss: 3.5721 - val_mean_squared_error: 3.5721\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.61290\n",
      "Epoch 70/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 14.6928 - mean_squared_error: 14.6928 - val_loss: 2.0726 - val_mean_squared_error: 2.0726\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.61290\n",
      "Epoch 71/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 3.1863 - mean_squared_error: 3.1863 - val_loss: 1.1191 - val_mean_squared_error: 1.1191\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.61290\n",
      "Epoch 72/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 143us/step - loss: 4.6666 - mean_squared_error: 4.6666 - val_loss: 0.6254 - val_mean_squared_error: 0.6254\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.61290\n",
      "Epoch 73/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.3341 - mean_squared_error: 3.3341 - val_loss: 0.6726 - val_mean_squared_error: 0.6726\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.61290\n",
      "Epoch 74/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 2.9152 - mean_squared_error: 2.9152 - val_loss: 1.1253 - val_mean_squared_error: 1.1253\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.61290\n",
      "Epoch 75/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.0059 - mean_squared_error: 8.0059 - val_loss: 0.7935 - val_mean_squared_error: 0.7935\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.61290\n",
      "Epoch 76/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.9489 - mean_squared_error: 3.9489 - val_loss: 0.7423 - val_mean_squared_error: 0.7423\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.61290\n",
      "Epoch 77/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.5900 - mean_squared_error: 9.5900 - val_loss: 1.0244 - val_mean_squared_error: 1.0244\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.61290\n",
      "Epoch 78/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 2.1277 - mean_squared_error: 2.1277 - val_loss: 0.6796 - val_mean_squared_error: 0.6796\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.61290\n",
      "Epoch 79/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.9009 - mean_squared_error: 6.9009 - val_loss: 0.5960 - val_mean_squared_error: 0.5960\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.61290 to 0.59599, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 80/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 3.2038 - mean_squared_error: 3.2038 - val_loss: 0.7918 - val_mean_squared_error: 0.7918\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.59599\n",
      "Epoch 81/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.4292 - mean_squared_error: 4.4292 - val_loss: 1.3608 - val_mean_squared_error: 1.3608\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.59599\n",
      "Epoch 82/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.4903 - mean_squared_error: 6.4903 - val_loss: 1.7532 - val_mean_squared_error: 1.7532\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.59599\n",
      "Epoch 83/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5.2964 - mean_squared_error: 5.2964 - val_loss: 1.4885 - val_mean_squared_error: 1.4885\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.59599\n",
      "Epoch 84/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.7657 - mean_squared_error: 4.7657 - val_loss: 1.2511 - val_mean_squared_error: 1.2511\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.59599\n",
      "Epoch 85/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5.9757 - mean_squared_error: 5.9757 - val_loss: 0.8236 - val_mean_squared_error: 0.8236\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.59599\n",
      "Epoch 86/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.0319 - mean_squared_error: 6.0319 - val_loss: 0.5902 - val_mean_squared_error: 0.5902\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.59599 to 0.59019, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 87/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 2.4415 - mean_squared_error: 2.4415 - val_loss: 0.9600 - val_mean_squared_error: 0.9600\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.59019\n",
      "Epoch 88/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.1858 - mean_squared_error: 6.1858 - val_loss: 1.6033 - val_mean_squared_error: 1.6033\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.59019\n",
      "Epoch 89/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.1161 - mean_squared_error: 3.1161 - val_loss: 2.2168 - val_mean_squared_error: 2.2168\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.59019\n",
      "Epoch 90/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 17.2312 - mean_squared_error: 17.2312 - val_loss: 1.6901 - val_mean_squared_error: 1.6901\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.59019\n",
      "Epoch 91/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.5860 - mean_squared_error: 5.5860 - val_loss: 0.9966 - val_mean_squared_error: 0.9966\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.59019\n",
      "Epoch 92/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 2.7496 - mean_squared_error: 2.7496 - val_loss: 0.6811 - val_mean_squared_error: 0.6811\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.59019\n",
      "Epoch 93/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4.7994 - mean_squared_error: 4.7994 - val_loss: 0.5779 - val_mean_squared_error: 0.5779\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.59019 to 0.57788, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 94/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 2.5876 - mean_squared_error: 2.5876 - val_loss: 0.6051 - val_mean_squared_error: 0.6051\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.57788\n",
      "Epoch 95/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.2446 - mean_squared_error: 7.2446 - val_loss: 0.9362 - val_mean_squared_error: 0.9362\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.57788\n",
      "Epoch 96/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5.6925 - mean_squared_error: 5.6925 - val_loss: 1.6880 - val_mean_squared_error: 1.6880\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.57788\n",
      "Epoch 97/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.8614 - mean_squared_error: 5.8614 - val_loss: 1.7523 - val_mean_squared_error: 1.7523\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.57788\n",
      "Epoch 98/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.9609 - mean_squared_error: 8.9609 - val_loss: 1.2109 - val_mean_squared_error: 1.2109\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.57788\n",
      "Epoch 99/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.4780 - mean_squared_error: 6.4780 - val_loss: 0.5970 - val_mean_squared_error: 0.5970\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.57788\n",
      "Epoch 100/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.0815 - mean_squared_error: 5.0815 - val_loss: 0.6336 - val_mean_squared_error: 0.6336\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.57788\n",
      "Epoch 101/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.1277 - mean_squared_error: 4.1277 - val_loss: 0.6196 - val_mean_squared_error: 0.6196\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.57788\n",
      "Epoch 102/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.4460 - mean_squared_error: 6.4460 - val_loss: 0.5850 - val_mean_squared_error: 0.5850\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.57788\n",
      "Epoch 103/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.9268 - mean_squared_error: 4.9268 - val_loss: 1.2766 - val_mean_squared_error: 1.2766\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.57788\n",
      "Epoch 104/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.9195 - mean_squared_error: 3.9195 - val_loss: 2.2371 - val_mean_squared_error: 2.2371\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.57788\n",
      "Epoch 105/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.8573 - mean_squared_error: 5.8573 - val_loss: 2.4068 - val_mean_squared_error: 2.4068\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.57788\n",
      "Epoch 106/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.9965 - mean_squared_error: 7.9965 - val_loss: 1.4972 - val_mean_squared_error: 1.4972\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.57788\n",
      "Epoch 107/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.4971 - mean_squared_error: 4.4971 - val_loss: 0.7357 - val_mean_squared_error: 0.7357\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.57788\n",
      "Epoch 108/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.5913 - mean_squared_error: 3.5913 - val_loss: 0.5927 - val_mean_squared_error: 0.5927\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.57788\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 143us/step - loss: 5.0427 - mean_squared_error: 5.0427 - val_loss: 0.8182 - val_mean_squared_error: 0.8182\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.57788\n",
      "Epoch 110/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.0170 - mean_squared_error: 5.0170 - val_loss: 1.2110 - val_mean_squared_error: 1.2110\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.57788\n",
      "Epoch 111/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.4367 - mean_squared_error: 4.4367 - val_loss: 1.8537 - val_mean_squared_error: 1.8537\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.57788\n",
      "Epoch 112/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.3340 - mean_squared_error: 6.3340 - val_loss: 1.8384 - val_mean_squared_error: 1.8384\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.57788\n",
      "Epoch 113/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.0406 - mean_squared_error: 6.0406 - val_loss: 1.3519 - val_mean_squared_error: 1.3519\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.57788\n",
      "Epoch 114/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 3.5115 - mean_squared_error: 3.5115 - val_loss: 0.6653 - val_mean_squared_error: 0.6653\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.57788\n",
      "Epoch 115/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.1978 - mean_squared_error: 4.1978 - val_loss: 0.6126 - val_mean_squared_error: 0.6126\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.57788\n",
      "Epoch 116/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.6429 - mean_squared_error: 3.6429 - val_loss: 0.6892 - val_mean_squared_error: 0.6892\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.57788\n",
      "Epoch 117/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.7794 - mean_squared_error: 3.7794 - val_loss: 0.7040 - val_mean_squared_error: 0.7040\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.57788\n",
      "Epoch 118/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.1064 - mean_squared_error: 4.1064 - val_loss: 0.6280 - val_mean_squared_error: 0.6280\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.57788\n",
      "Epoch 119/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.6439 - mean_squared_error: 4.6439 - val_loss: 0.5959 - val_mean_squared_error: 0.5959\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.57788\n",
      "Epoch 120/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 7.9294 - mean_squared_error: 7.9294 - val_loss: 0.5555 - val_mean_squared_error: 0.5555\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.57788 to 0.55555, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 121/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 3.8053 - mean_squared_error: 3.8053 - val_loss: 0.7064 - val_mean_squared_error: 0.7064\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.55555\n",
      "Epoch 122/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.7599 - mean_squared_error: 3.7599 - val_loss: 1.0401 - val_mean_squared_error: 1.0401\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.55555\n",
      "Epoch 123/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.8308 - mean_squared_error: 5.8308 - val_loss: 1.0597 - val_mean_squared_error: 1.0597\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.55555\n",
      "Epoch 124/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.3280 - mean_squared_error: 3.3280 - val_loss: 0.9761 - val_mean_squared_error: 0.9761\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.55555\n",
      "Epoch 125/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.7074 - mean_squared_error: 3.7074 - val_loss: 0.8962 - val_mean_squared_error: 0.8962\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.55555\n",
      "Epoch 126/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.4755 - mean_squared_error: 4.4755 - val_loss: 0.7126 - val_mean_squared_error: 0.7126\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.55555\n",
      "Epoch 127/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 2.5870 - mean_squared_error: 2.5870 - val_loss: 0.6132 - val_mean_squared_error: 0.6132\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.55555\n",
      "Epoch 128/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.3496 - mean_squared_error: 3.3496 - val_loss: 0.5651 - val_mean_squared_error: 0.5651\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.55555\n",
      "Epoch 129/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5.1529 - mean_squared_error: 5.1529 - val_loss: 0.5474 - val_mean_squared_error: 0.5474\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.55555 to 0.54744, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 130/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.4444 - mean_squared_error: 6.4444 - val_loss: 0.5411 - val_mean_squared_error: 0.5411\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.54744 to 0.54105, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 131/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.7351 - mean_squared_error: 3.7351 - val_loss: 0.7259 - val_mean_squared_error: 0.7259\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.54105\n",
      "Epoch 132/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 2.1431 - mean_squared_error: 2.1431 - val_loss: 2.0137 - val_mean_squared_error: 2.0137\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.54105\n",
      "Epoch 133/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 2.4006 - mean_squared_error: 2.4006 - val_loss: 2.5676 - val_mean_squared_error: 2.5676\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.54105\n",
      "Epoch 134/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.9736 - mean_squared_error: 4.9736 - val_loss: 2.0158 - val_mean_squared_error: 2.0158\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.54105\n",
      "Epoch 135/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 9.4420 - mean_squared_error: 9.4420 - val_loss: 0.9231 - val_mean_squared_error: 0.9231\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.54105\n",
      "Epoch 136/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 11.4742 - mean_squared_error: 11.4742 - val_loss: 0.5859 - val_mean_squared_error: 0.5859\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.54105\n",
      "Epoch 137/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.2008 - mean_squared_error: 5.2008 - val_loss: 0.5640 - val_mean_squared_error: 0.5640\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.54105\n",
      "Epoch 138/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 5.8327 - mean_squared_error: 5.8327 - val_loss: 1.0265 - val_mean_squared_error: 1.0265\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.54105\n",
      "Epoch 139/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 2.6477 - mean_squared_error: 2.6477 - val_loss: 2.7495 - val_mean_squared_error: 2.7495\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.54105\n",
      "Epoch 140/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.9330 - mean_squared_error: 6.9330 - val_loss: 4.3822 - val_mean_squared_error: 4.3822\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.54105\n",
      "Epoch 141/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 10.4350 - mean_squared_error: 10.4350 - val_loss: 5.0641 - val_mean_squared_error: 5.0641\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.54105\n",
      "Epoch 142/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 14.3399 - mean_squared_error: 14.3399 - val_loss: 3.7356 - val_mean_squared_error: 3.7356\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.54105\n",
      "Epoch 143/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 11.5070 - mean_squared_error: 11.5070 - val_loss: 1.6189 - val_mean_squared_error: 1.6189\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.54105\n",
      "Epoch 144/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 18.0129 - mean_squared_error: 18.0129 - val_loss: 0.5781 - val_mean_squared_error: 0.5781\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.54105\n",
      "Epoch 145/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.1381 - mean_squared_error: 4.1381 - val_loss: 0.9376 - val_mean_squared_error: 0.9376\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.54105\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 190us/step - loss: 9.5745 - mean_squared_error: 9.5745 - val_loss: 2.2455 - val_mean_squared_error: 2.2455\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.54105\n",
      "Epoch 147/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.7784 - mean_squared_error: 8.7784 - val_loss: 2.7598 - val_mean_squared_error: 2.7598\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.54105\n",
      "Epoch 148/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.9019 - mean_squared_error: 3.9019 - val_loss: 2.1857 - val_mean_squared_error: 2.1857\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.54105\n",
      "Epoch 149/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 7.5957 - mean_squared_error: 7.5957 - val_loss: 1.1458 - val_mean_squared_error: 1.1458\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.54105\n",
      "Epoch 150/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4.3971 - mean_squared_error: 4.3971 - val_loss: 0.5353 - val_mean_squared_error: 0.5353\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.54105 to 0.53535, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 151/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 4.8543 - mean_squared_error: 4.8543 - val_loss: 1.5465 - val_mean_squared_error: 1.5465\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.53535\n",
      "Epoch 152/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.3718 - mean_squared_error: 6.3718 - val_loss: 3.1904 - val_mean_squared_error: 3.1904\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.53535\n",
      "Epoch 153/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.2883 - mean_squared_error: 7.2883 - val_loss: 4.0508 - val_mean_squared_error: 4.0508\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.53535\n",
      "Epoch 154/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 15.8007 - mean_squared_error: 15.8007 - val_loss: 3.6363 - val_mean_squared_error: 3.6363\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.53535\n",
      "Epoch 155/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.1628 - mean_squared_error: 5.1628 - val_loss: 1.9851 - val_mean_squared_error: 1.9851\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.53535\n",
      "Epoch 156/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.6503 - mean_squared_error: 8.6503 - val_loss: 0.5740 - val_mean_squared_error: 0.5740\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.53535\n",
      "Epoch 157/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 1.9494 - mean_squared_error: 1.9494 - val_loss: 0.7316 - val_mean_squared_error: 0.7316\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.53535\n",
      "Epoch 158/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 2.7960 - mean_squared_error: 2.7960 - val_loss: 1.2515 - val_mean_squared_error: 1.2515\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.53535\n",
      "Epoch 159/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.1179 - mean_squared_error: 4.1179 - val_loss: 1.7429 - val_mean_squared_error: 1.7429\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.53535\n",
      "Epoch 160/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 7.1533 - mean_squared_error: 7.1533 - val_loss: 2.2622 - val_mean_squared_error: 2.2622\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.53535\n",
      "Epoch 161/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.2082 - mean_squared_error: 9.2082 - val_loss: 1.6349 - val_mean_squared_error: 1.6349\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.53535\n",
      "Epoch 162/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 13.0406 - mean_squared_error: 13.0406 - val_loss: 0.5520 - val_mean_squared_error: 0.5520\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.53535\n",
      "Epoch 163/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 2.8448 - mean_squared_error: 2.8448 - val_loss: 0.9840 - val_mean_squared_error: 0.9840\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.53535\n",
      "Epoch 164/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 12.3076 - mean_squared_error: 12.3076 - val_loss: 2.0677 - val_mean_squared_error: 2.0677\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.53535\n",
      "Epoch 165/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 9.8978 - mean_squared_error: 9.8978 - val_loss: 2.8119 - val_mean_squared_error: 2.8119\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.53535\n",
      "Epoch 166/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.4415 - mean_squared_error: 7.4415 - val_loss: 2.9428 - val_mean_squared_error: 2.9428\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.53535\n",
      "Epoch 167/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 12.7182 - mean_squared_error: 12.7182 - val_loss: 2.3225 - val_mean_squared_error: 2.3225\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.53535\n",
      "Epoch 168/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 12.7607 - mean_squared_error: 12.7607 - val_loss: 1.3868 - val_mean_squared_error: 1.3868\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.53535\n",
      "Epoch 169/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.2518 - mean_squared_error: 5.2518 - val_loss: 0.8227 - val_mean_squared_error: 0.8227\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.53535\n",
      "Epoch 170/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.6924 - mean_squared_error: 4.6924 - val_loss: 0.5379 - val_mean_squared_error: 0.5379\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.53535\n",
      "Epoch 171/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 3.6539 - mean_squared_error: 3.6539 - val_loss: 0.5400 - val_mean_squared_error: 0.5400\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.53535\n",
      "Epoch 172/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 8.3915 - mean_squared_error: 8.3915 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.53535\n",
      "Epoch 173/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5.0948 - mean_squared_error: 5.0948 - val_loss: 0.5975 - val_mean_squared_error: 0.5975\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.53535\n",
      "Epoch 174/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.4458 - mean_squared_error: 4.4458 - val_loss: 0.6368 - val_mean_squared_error: 0.6368\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.53535\n",
      "Epoch 175/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.1879 - mean_squared_error: 5.1879 - val_loss: 1.2435 - val_mean_squared_error: 1.2435\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.53535\n",
      "Epoch 176/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 12.8695 - mean_squared_error: 12.8695 - val_loss: 1.6716 - val_mean_squared_error: 1.6716\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.53535\n",
      "Epoch 177/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.1426 - mean_squared_error: 4.1426 - val_loss: 2.0301 - val_mean_squared_error: 2.0301\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.53535\n",
      "Epoch 178/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.0459 - mean_squared_error: 9.0459 - val_loss: 1.4845 - val_mean_squared_error: 1.4845\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.53535\n",
      "Epoch 179/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.9666 - mean_squared_error: 9.9666 - val_loss: 0.5089 - val_mean_squared_error: 0.5089\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.53535 to 0.50889, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 180/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 2.4590 - mean_squared_error: 2.4590 - val_loss: 1.7520 - val_mean_squared_error: 1.7520\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.50889\n",
      "Epoch 181/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 6.7592 - mean_squared_error: 6.7592 - val_loss: 2.3423 - val_mean_squared_error: 2.3423\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.50889\n",
      "Epoch 182/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 4.7007 - mean_squared_error: 4.7007 - val_loss: 1.1937 - val_mean_squared_error: 1.1937\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.50889\n",
      "Epoch 183/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 143us/step - loss: 7.8082 - mean_squared_error: 7.8082 - val_loss: 0.5635 - val_mean_squared_error: 0.5635\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.50889\n",
      "Epoch 184/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.0388 - mean_squared_error: 7.0388 - val_loss: 0.6773 - val_mean_squared_error: 0.6773\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.50889\n",
      "Epoch 185/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 2.5607 - mean_squared_error: 2.5607 - val_loss: 2.1709 - val_mean_squared_error: 2.1709\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.50889\n",
      "Epoch 186/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.9742 - mean_squared_error: 7.9742 - val_loss: 2.4417 - val_mean_squared_error: 2.4417\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.50889\n",
      "Epoch 187/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.4944 - mean_squared_error: 6.4944 - val_loss: 1.4095 - val_mean_squared_error: 1.4095\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.50889\n",
      "Epoch 188/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 4.6563 - mean_squared_error: 4.6563 - val_loss: 0.8045 - val_mean_squared_error: 0.8045\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.50889\n",
      "Epoch 189/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.8585 - mean_squared_error: 8.8585 - val_loss: 0.5554 - val_mean_squared_error: 0.5554\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.50889\n",
      "Epoch 190/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5.3303 - mean_squared_error: 5.3303 - val_loss: 0.5151 - val_mean_squared_error: 0.5151\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.50889\n",
      "Epoch 191/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.3468 - mean_squared_error: 4.3468 - val_loss: 0.5079 - val_mean_squared_error: 0.5079\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.50889 to 0.50793, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 192/300\n",
      "21/21 [==============================] - 0s 236us/step - loss: 4.1908 - mean_squared_error: 4.1908 - val_loss: 0.5286 - val_mean_squared_error: 0.5286\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.50793\n",
      "Epoch 193/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.3405 - mean_squared_error: 4.3405 - val_loss: 0.6252 - val_mean_squared_error: 0.6252\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.50793\n",
      "Epoch 194/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.4370 - mean_squared_error: 6.4370 - val_loss: 0.8641 - val_mean_squared_error: 0.8641\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.50793\n",
      "Epoch 195/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.1737 - mean_squared_error: 5.1737 - val_loss: 0.7064 - val_mean_squared_error: 0.7064\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.50793\n",
      "Epoch 196/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 2.5054 - mean_squared_error: 2.5054 - val_loss: 0.5001 - val_mean_squared_error: 0.5001\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.50793 to 0.50011, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 197/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.9051 - mean_squared_error: 4.9051 - val_loss: 0.5104 - val_mean_squared_error: 0.5104\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.50011\n",
      "Epoch 198/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 3.3699 - mean_squared_error: 3.3699 - val_loss: 0.5044 - val_mean_squared_error: 0.5044\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.50011\n",
      "Epoch 199/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 7.4812 - mean_squared_error: 7.4812 - val_loss: 0.5669 - val_mean_squared_error: 0.5669\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.50011\n",
      "Epoch 200/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.9316 - mean_squared_error: 3.9316 - val_loss: 0.6200 - val_mean_squared_error: 0.6200\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.50011\n",
      "Epoch 201/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 1.8283 - mean_squared_error: 1.8283 - val_loss: 0.5277 - val_mean_squared_error: 0.5277\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.50011\n",
      "Epoch 202/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.3175 - mean_squared_error: 3.3175 - val_loss: 0.5980 - val_mean_squared_error: 0.5980\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.50011\n",
      "Epoch 203/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.3691 - mean_squared_error: 5.3691 - val_loss: 1.4400 - val_mean_squared_error: 1.4400\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.50011\n",
      "Epoch 204/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 9.0183 - mean_squared_error: 9.0183 - val_loss: 1.8963 - val_mean_squared_error: 1.8963\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.50011\n",
      "Epoch 205/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.7627 - mean_squared_error: 3.7627 - val_loss: 1.8053 - val_mean_squared_error: 1.8053\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.50011\n",
      "Epoch 206/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 5.9682 - mean_squared_error: 5.9682 - val_loss: 1.3057 - val_mean_squared_error: 1.3057\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.50011\n",
      "Epoch 207/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.7681 - mean_squared_error: 5.7681 - val_loss: 0.8298 - val_mean_squared_error: 0.8298\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.50011\n",
      "Epoch 208/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 9.2683 - mean_squared_error: 9.2683 - val_loss: 0.5420 - val_mean_squared_error: 0.5420\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.50011\n",
      "Epoch 209/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.9306 - mean_squared_error: 3.9306 - val_loss: 0.4924 - val_mean_squared_error: 0.4924\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.50011 to 0.49241, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 210/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.4278 - mean_squared_error: 8.4278 - val_loss: 0.6008 - val_mean_squared_error: 0.6008\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.49241\n",
      "Epoch 211/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.4831 - mean_squared_error: 3.4831 - val_loss: 0.9902 - val_mean_squared_error: 0.9902\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.49241\n",
      "Epoch 212/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 8.4814 - mean_squared_error: 8.4814 - val_loss: 2.0101 - val_mean_squared_error: 2.0101\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.49241\n",
      "Epoch 213/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 9.3757 - mean_squared_error: 9.3757 - val_loss: 3.1911 - val_mean_squared_error: 3.1911\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.49241\n",
      "Epoch 214/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.4369 - mean_squared_error: 7.4369 - val_loss: 2.9696 - val_mean_squared_error: 2.9696\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.49241\n",
      "Epoch 215/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 8.2987 - mean_squared_error: 8.2987 - val_loss: 1.2734 - val_mean_squared_error: 1.2734\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.49241\n",
      "Epoch 216/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.5903 - mean_squared_error: 4.5903 - val_loss: 0.4987 - val_mean_squared_error: 0.4987\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.49241\n",
      "Epoch 217/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.8547 - mean_squared_error: 3.8547 - val_loss: 1.6868 - val_mean_squared_error: 1.6868\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.49241\n",
      "Epoch 218/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.3544 - mean_squared_error: 6.3544 - val_loss: 3.3905 - val_mean_squared_error: 3.3905\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.49241\n",
      "Epoch 219/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 16.8882 - mean_squared_error: 16.8882 - val_loss: 3.3528 - val_mean_squared_error: 3.3528\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.49241\n",
      "Epoch 220/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 190us/step - loss: 7.8201 - mean_squared_error: 7.8201 - val_loss: 1.8366 - val_mean_squared_error: 1.8366\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.49241\n",
      "Epoch 221/300\n",
      "21/21 [==============================] - 0s 191us/step - loss: 7.5445 - mean_squared_error: 7.5445 - val_loss: 0.5504 - val_mean_squared_error: 0.5504\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.49241\n",
      "Epoch 222/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.3690 - mean_squared_error: 3.3690 - val_loss: 1.2096 - val_mean_squared_error: 1.2096\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.49241\n",
      "Epoch 223/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 8.4999 - mean_squared_error: 8.4999 - val_loss: 2.7715 - val_mean_squared_error: 2.7715\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.49241\n",
      "Epoch 224/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 10.0898 - mean_squared_error: 10.0898 - val_loss: 2.4253 - val_mean_squared_error: 2.4253\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.49241\n",
      "Epoch 225/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 9.3239 - mean_squared_error: 9.3239 - val_loss: 1.2796 - val_mean_squared_error: 1.2796\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.49241\n",
      "Epoch 226/300\n",
      "21/21 [==============================] - 0s 141us/step - loss: 5.2100 - mean_squared_error: 5.2100 - val_loss: 0.6593 - val_mean_squared_error: 0.6593\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.49241\n",
      "Epoch 227/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 3.6052 - mean_squared_error: 3.6052 - val_loss: 0.4728 - val_mean_squared_error: 0.4728\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.49241 to 0.47277, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 228/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 2.5076 - mean_squared_error: 2.5076 - val_loss: 0.7258 - val_mean_squared_error: 0.7258\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.47277\n",
      "Epoch 229/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 2.5231 - mean_squared_error: 2.5231 - val_loss: 1.0400 - val_mean_squared_error: 1.0400\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.47277\n",
      "Epoch 230/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 8.5129 - mean_squared_error: 8.5129 - val_loss: 1.0028 - val_mean_squared_error: 1.0028\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.47277\n",
      "Epoch 231/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 2.7309 - mean_squared_error: 2.7309 - val_loss: 0.8306 - val_mean_squared_error: 0.8306\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.47277\n",
      "Epoch 232/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.9296 - mean_squared_error: 3.9296 - val_loss: 0.4894 - val_mean_squared_error: 0.4894\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.47277\n",
      "Epoch 233/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.1682 - mean_squared_error: 5.1682 - val_loss: 0.6772 - val_mean_squared_error: 0.6772\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.47277\n",
      "Epoch 234/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.0550 - mean_squared_error: 4.0550 - val_loss: 0.7934 - val_mean_squared_error: 0.7934\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.47277\n",
      "Epoch 235/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.5008 - mean_squared_error: 3.5008 - val_loss: 0.6389 - val_mean_squared_error: 0.6389\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.47277\n",
      "Epoch 236/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.1597 - mean_squared_error: 7.1597 - val_loss: 0.4618 - val_mean_squared_error: 0.4618\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.47277 to 0.46178, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 237/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.9646 - mean_squared_error: 6.9646 - val_loss: 0.7008 - val_mean_squared_error: 0.7008\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.46178\n",
      "Epoch 238/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 8.3394 - mean_squared_error: 8.3394 - val_loss: 0.5746 - val_mean_squared_error: 0.5746\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.46178\n",
      "Epoch 239/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 4.0282 - mean_squared_error: 4.0282 - val_loss: 0.5017 - val_mean_squared_error: 0.5017\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.46178\n",
      "Epoch 240/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.1510 - mean_squared_error: 3.1510 - val_loss: 1.0349 - val_mean_squared_error: 1.0349\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.46178\n",
      "Epoch 241/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.0338 - mean_squared_error: 4.0338 - val_loss: 1.7491 - val_mean_squared_error: 1.7491\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.46178\n",
      "Epoch 242/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.3090 - mean_squared_error: 7.3090 - val_loss: 1.4130 - val_mean_squared_error: 1.4130\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.46178\n",
      "Epoch 243/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.2699 - mean_squared_error: 6.2699 - val_loss: 0.7977 - val_mean_squared_error: 0.7977\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.46178\n",
      "Epoch 244/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 2.1924 - mean_squared_error: 2.1924 - val_loss: 0.5272 - val_mean_squared_error: 0.5272\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.46178\n",
      "Epoch 245/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 9.1416 - mean_squared_error: 9.1416 - val_loss: 0.5857 - val_mean_squared_error: 0.5857\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.46178\n",
      "Epoch 246/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 5.1013 - mean_squared_error: 5.1013 - val_loss: 0.6009 - val_mean_squared_error: 0.6009\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.46178\n",
      "Epoch 247/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.9996 - mean_squared_error: 4.9996 - val_loss: 0.4896 - val_mean_squared_error: 0.4896\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.46178\n",
      "Epoch 248/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.6434 - mean_squared_error: 3.6434 - val_loss: 0.4645 - val_mean_squared_error: 0.4645\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.46178\n",
      "Epoch 249/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.8436 - mean_squared_error: 6.8436 - val_loss: 0.4719 - val_mean_squared_error: 0.4719\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.46178\n",
      "Epoch 250/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.4148 - mean_squared_error: 5.4148 - val_loss: 0.5380 - val_mean_squared_error: 0.5380\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.46178\n",
      "Epoch 251/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.8457 - mean_squared_error: 4.8457 - val_loss: 0.5464 - val_mean_squared_error: 0.5464\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.46178\n",
      "Epoch 252/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 1.2250 - mean_squared_error: 1.2250 - val_loss: 0.4837 - val_mean_squared_error: 0.4837\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.46178\n",
      "Epoch 253/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 2.4235 - mean_squared_error: 2.4235 - val_loss: 0.5187 - val_mean_squared_error: 0.5187\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.46178\n",
      "Epoch 254/300\n",
      "21/21 [==============================] - 0s 189us/step - loss: 3.9394 - mean_squared_error: 3.9394 - val_loss: 1.0502 - val_mean_squared_error: 1.0502\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.46178\n",
      "Epoch 255/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.9006 - mean_squared_error: 4.9006 - val_loss: 1.3696 - val_mean_squared_error: 1.3696\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.46178\n",
      "Epoch 256/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 11.4834 - mean_squared_error: 11.4834 - val_loss: 0.7721 - val_mean_squared_error: 0.7721\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.46178\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 190us/step - loss: 3.3598 - mean_squared_error: 3.3598 - val_loss: 0.7460 - val_mean_squared_error: 0.7460\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.46178\n",
      "Epoch 258/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.4317 - mean_squared_error: 3.4317 - val_loss: 3.4448 - val_mean_squared_error: 3.4448\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.46178\n",
      "Epoch 259/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 12.2324 - mean_squared_error: 12.2324 - val_loss: 4.0003 - val_mean_squared_error: 4.0003\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.46178\n",
      "Epoch 260/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 16.5481 - mean_squared_error: 16.5481 - val_loss: 1.5632 - val_mean_squared_error: 1.5632\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.46178\n",
      "Epoch 261/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.7091 - mean_squared_error: 7.7091 - val_loss: 0.7363 - val_mean_squared_error: 0.7363\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.46178\n",
      "Epoch 262/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.0371 - mean_squared_error: 6.0371 - val_loss: 0.6376 - val_mean_squared_error: 0.6376\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.46178\n",
      "Epoch 263/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 9.5948 - mean_squared_error: 9.5948 - val_loss: 1.2847 - val_mean_squared_error: 1.2847\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.46178\n",
      "Epoch 264/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 3.6973 - mean_squared_error: 3.6973 - val_loss: 3.3893 - val_mean_squared_error: 3.3893\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.46178\n",
      "Epoch 265/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 8.9524 - mean_squared_error: 8.9524 - val_loss: 3.7525 - val_mean_squared_error: 3.7525\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.46178\n",
      "Epoch 266/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 7.1307 - mean_squared_error: 7.1307 - val_loss: 4.7122 - val_mean_squared_error: 4.7122\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.46178\n",
      "Epoch 267/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 19.0261 - mean_squared_error: 19.0261 - val_loss: 0.8541 - val_mean_squared_error: 0.8541\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.46178\n",
      "Epoch 268/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.9014 - mean_squared_error: 7.9014 - val_loss: 3.4894 - val_mean_squared_error: 3.4894\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.46178\n",
      "Epoch 269/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 13.8211 - mean_squared_error: 13.8211 - val_loss: 10.3910 - val_mean_squared_error: 10.3910\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.46178\n",
      "Epoch 270/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 19.5574 - mean_squared_error: 19.5574 - val_loss: 12.7612 - val_mean_squared_error: 12.7612\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.46178\n",
      "Epoch 271/300\n",
      "21/21 [==============================] - 0s 285us/step - loss: 25.0364 - mean_squared_error: 25.0364 - val_loss: 8.5533 - val_mean_squared_error: 8.5533\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.46178\n",
      "Epoch 272/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 15.3459 - mean_squared_error: 15.3459 - val_loss: 2.5054 - val_mean_squared_error: 2.5054\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.46178\n",
      "Epoch 273/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 7.3936 - mean_squared_error: 7.3936 - val_loss: 0.4970 - val_mean_squared_error: 0.4970\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.46178\n",
      "Epoch 274/300\n",
      "21/21 [==============================] - 0s 143us/step - loss: 5.6304 - mean_squared_error: 5.6304 - val_loss: 4.0321 - val_mean_squared_error: 4.0321\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.46178\n",
      "Epoch 275/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 10.3760 - mean_squared_error: 10.3760 - val_loss: 8.3475 - val_mean_squared_error: 8.3475\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.46178\n",
      "Epoch 276/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 12.3778 - mean_squared_error: 12.3778 - val_loss: 9.2563 - val_mean_squared_error: 9.2563\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.46178\n",
      "Epoch 277/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 27.9525 - mean_squared_error: 27.9525 - val_loss: 5.3302 - val_mean_squared_error: 5.3302\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.46178\n",
      "Epoch 278/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 9.7269 - mean_squared_error: 9.7269 - val_loss: 1.3135 - val_mean_squared_error: 1.3135\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.46178\n",
      "Epoch 279/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 8.0045 - mean_squared_error: 8.0045 - val_loss: 0.6006 - val_mean_squared_error: 0.6006\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.46178\n",
      "Epoch 280/300\n",
      "21/21 [==============================] - 0s 238us/step - loss: 4.9401 - mean_squared_error: 4.9401 - val_loss: 1.9907 - val_mean_squared_error: 1.9907\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.46178\n",
      "Epoch 281/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 7.5946 - mean_squared_error: 7.5946 - val_loss: 2.7215 - val_mean_squared_error: 2.7215\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.46178\n",
      "Epoch 282/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 8.7781 - mean_squared_error: 8.7781 - val_loss: 2.1031 - val_mean_squared_error: 2.1031\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.46178\n",
      "Epoch 283/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 10.4875 - mean_squared_error: 10.4875 - val_loss: 0.9218 - val_mean_squared_error: 0.9218\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.46178\n",
      "Epoch 284/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 5.0884 - mean_squared_error: 5.0884 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.46178 to 0.41964, saving model to saved_models/weights_test_data_1.hdf5\n",
      "Epoch 285/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.6193 - mean_squared_error: 3.6193 - val_loss: 0.8672 - val_mean_squared_error: 0.8672\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.41964\n",
      "Epoch 286/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 9.5897 - mean_squared_error: 9.5897 - val_loss: 1.5806 - val_mean_squared_error: 1.5806\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.41964\n",
      "Epoch 287/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 7.1948 - mean_squared_error: 7.1948 - val_loss: 1.6168 - val_mean_squared_error: 1.6168\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.41964\n",
      "Epoch 288/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 9.5750 - mean_squared_error: 9.5750 - val_loss: 0.4209 - val_mean_squared_error: 0.4209\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.41964\n",
      "Epoch 289/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 6.0732 - mean_squared_error: 6.0732 - val_loss: 1.2606 - val_mean_squared_error: 1.2606\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.41964\n",
      "Epoch 290/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.3679 - mean_squared_error: 4.3679 - val_loss: 1.8110 - val_mean_squared_error: 1.8110\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.41964\n",
      "Epoch 291/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 19.0677 - mean_squared_error: 19.0677 - val_loss: 1.4604 - val_mean_squared_error: 1.4604\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.41964\n",
      "Epoch 292/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.2278 - mean_squared_error: 6.2278 - val_loss: 0.7989 - val_mean_squared_error: 0.7989\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.41964\n",
      "Epoch 293/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 1.1071 - mean_squared_error: 1.1071 - val_loss: 0.4779 - val_mean_squared_error: 0.4779\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.41964\n",
      "Epoch 294/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 142us/step - loss: 8.9330 - mean_squared_error: 8.9330 - val_loss: 0.4547 - val_mean_squared_error: 0.4547\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.41964\n",
      "Epoch 295/300\n",
      "21/21 [==============================] - 0s 237us/step - loss: 6.6327 - mean_squared_error: 6.6327 - val_loss: 0.8245 - val_mean_squared_error: 0.8245\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.41964\n",
      "Epoch 296/300\n",
      "21/21 [==============================] - 0s 142us/step - loss: 6.1264 - mean_squared_error: 6.1264 - val_loss: 0.8688 - val_mean_squared_error: 0.8688\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.41964\n",
      "Epoch 297/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.1481 - mean_squared_error: 4.1481 - val_loss: 0.7206 - val_mean_squared_error: 0.7206\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.41964\n",
      "Epoch 298/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 4.2147 - mean_squared_error: 4.2147 - val_loss: 0.6708 - val_mean_squared_error: 0.6708\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.41964\n",
      "Epoch 299/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 3.7777 - mean_squared_error: 3.7777 - val_loss: 3.9195 - val_mean_squared_error: 3.9195\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.41964\n",
      "Epoch 300/300\n",
      "21/21 [==============================] - 0s 190us/step - loss: 11.0789 - mean_squared_error: 11.0789 - val_loss: 6.6075 - val_mean_squared_error: 6.6075\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.41964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e81c015320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 300\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights_test_data_1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer, history], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e81e5d70b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(history.history['val_loss'], color = 'blue', label = \"Validation loss\")\n",
    "plt.plot(history.history['loss'], color = 'orange', label = \"Training loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate test data\n",
      "3/3 [==============================] - 0s 666us/step\n",
      "test loss, test acc: [13.316363334655762, 13.316363334655762]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate test data\")\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for test data\n",
      "[[19.556711 ]\n",
      " [ 7.8667955]\n",
      " [ 1.2263831]]\n",
      "Test data\n",
      "[[25.7327]\n",
      " [ 9.2089]\n",
      " [ 1.2971]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions for test data\")\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "print(\"Test data\")\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
